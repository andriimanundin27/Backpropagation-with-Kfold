{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from math import exp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "df = pd.read_csv ('F:/ML/data.csv', header=None)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3               4   f1   f2   f3\n",
      "0    5.1  3.5  1.4  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "1    4.9  3.0  1.4  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "2    4.7  3.2  1.3  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "3    4.6  3.1  1.5  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "4    5.0  3.6  1.4  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "5    5.4  3.9  1.7  0.4     Iris-setosa  1.0  0.0  0.0\n",
      "6    4.6  3.4  1.4  0.3     Iris-setosa  1.0  0.0  0.0\n",
      "7    5.0  3.4  1.5  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "8    4.4  2.9  1.4  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "9    4.9  3.1  1.5  0.1     Iris-setosa  1.0  0.0  0.0\n",
      "10   5.4  3.7  1.5  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "11   4.8  3.4  1.6  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "12   4.8  3.0  1.4  0.1     Iris-setosa  1.0  0.0  0.0\n",
      "13   4.3  3.0  1.1  0.1     Iris-setosa  1.0  0.0  0.0\n",
      "14   5.8  4.0  1.2  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "15   5.7  4.4  1.5  0.4     Iris-setosa  1.0  0.0  0.0\n",
      "16   5.4  3.9  1.3  0.4     Iris-setosa  1.0  0.0  0.0\n",
      "17   5.1  3.5  1.4  0.3     Iris-setosa  1.0  0.0  0.0\n",
      "18   5.7  3.8  1.7  0.3     Iris-setosa  1.0  0.0  0.0\n",
      "19   5.1  3.8  1.5  0.3     Iris-setosa  1.0  0.0  0.0\n",
      "20   5.4  3.4  1.7  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "21   5.1  3.7  1.5  0.4     Iris-setosa  1.0  0.0  0.0\n",
      "22   4.6  3.6  1.0  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "23   5.1  3.3  1.7  0.5     Iris-setosa  1.0  0.0  0.0\n",
      "24   4.8  3.4  1.9  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "25   5.0  3.0  1.6  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "26   5.0  3.4  1.6  0.4     Iris-setosa  1.0  0.0  0.0\n",
      "27   5.2  3.5  1.5  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "28   5.2  3.4  1.4  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "29   4.7  3.2  1.6  0.2     Iris-setosa  1.0  0.0  0.0\n",
      "..   ...  ...  ...  ...             ...  ...  ...  ...\n",
      "120  6.9  3.2  5.7  2.3  Iris-virginica  0.0  0.0  1.0\n",
      "121  5.6  2.8  4.9  2.0  Iris-virginica  0.0  0.0  1.0\n",
      "122  7.7  2.8  6.7  2.0  Iris-virginica  0.0  0.0  1.0\n",
      "123  6.3  2.7  4.9  1.8  Iris-virginica  0.0  0.0  1.0\n",
      "124  6.7  3.3  5.7  2.1  Iris-virginica  0.0  0.0  1.0\n",
      "125  7.2  3.2  6.0  1.8  Iris-virginica  0.0  0.0  1.0\n",
      "126  6.2  2.8  4.8  1.8  Iris-virginica  0.0  0.0  1.0\n",
      "127  6.1  3.0  4.9  1.8  Iris-virginica  0.0  0.0  1.0\n",
      "128  6.4  2.8  5.6  2.1  Iris-virginica  0.0  0.0  1.0\n",
      "129  7.2  3.0  5.8  1.6  Iris-virginica  0.0  0.0  1.0\n",
      "130  7.4  2.8  6.1  1.9  Iris-virginica  0.0  0.0  1.0\n",
      "131  7.9  3.8  6.4  2.0  Iris-virginica  0.0  0.0  1.0\n",
      "132  6.4  2.8  5.6  2.2  Iris-virginica  0.0  0.0  1.0\n",
      "133  6.3  2.8  5.1  1.5  Iris-virginica  0.0  0.0  1.0\n",
      "134  6.1  2.6  5.6  1.4  Iris-virginica  0.0  0.0  1.0\n",
      "135  7.7  3.0  6.1  2.3  Iris-virginica  0.0  0.0  1.0\n",
      "136  6.3  3.4  5.6  2.4  Iris-virginica  0.0  0.0  1.0\n",
      "137  6.4  3.1  5.5  1.8  Iris-virginica  0.0  0.0  1.0\n",
      "138  6.0  3.0  4.8  1.8  Iris-virginica  0.0  0.0  1.0\n",
      "139  6.9  3.1  5.4  2.1  Iris-virginica  0.0  0.0  1.0\n",
      "140  6.7  3.1  5.6  2.4  Iris-virginica  0.0  0.0  1.0\n",
      "141  6.9  3.1  5.1  2.3  Iris-virginica  0.0  0.0  1.0\n",
      "142  5.8  2.7  5.1  1.9  Iris-virginica  0.0  0.0  1.0\n",
      "143  6.8  3.2  5.9  2.3  Iris-virginica  0.0  0.0  1.0\n",
      "144  6.7  3.3  5.7  2.5  Iris-virginica  0.0  0.0  1.0\n",
      "145  6.7  3.0  5.2  2.3  Iris-virginica  0.0  0.0  1.0\n",
      "146  6.3  2.5  5.0  1.9  Iris-virginica  0.0  0.0  1.0\n",
      "147  6.5  3.0  5.2  2.0  Iris-virginica  0.0  0.0  1.0\n",
      "148  6.2  3.4  5.4  2.3  Iris-virginica  0.0  0.0  1.0\n",
      "149  5.9  3.0  5.1  1.8  Iris-virginica  0.0  0.0  1.0\n",
      "\n",
      "[150 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "DATA = 150\n",
    "ALPHA = 0.01\n",
    "EPOCH = 100\n",
    "\n",
    "#create fact\n",
    "f1 = np.empty(DATA)\n",
    "f2 = np.empty(DATA)\n",
    "f3 = np.empty(DATA)\n",
    "\n",
    "f1[0:50] = 1\n",
    "f1[50:150] = 0\n",
    "f2[0:50] = 0\n",
    "f2[50:100] = 1\n",
    "f2[100:150] = 0\n",
    "f3[0:100] = 0\n",
    "f3[100:150] = 1\n",
    "\n",
    "#Fact to Dataframe\n",
    "d = {'f1': f1, 'f2': f2, 'f3': f3}\n",
    "fdf = pd.DataFrame(data=d)\n",
    "#print(fdf)\n",
    "\n",
    "#Join df and fact\n",
    "df = pd.concat([df, fdf], axis=1, join='inner')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h (x, t) :\n",
    "    return  np.dot(x, t)\n",
    "def sigmoid (h) :\n",
    "    return 1 / (1 + exp(-h))\n",
    "def table_count(data):\n",
    "    return data.iloc[:,0].size\n",
    "def theta_bias_initiation():\n",
    "    theta1 = np.array([[0.1, 0.2, 0.3, 0.4], \n",
    "                       [0.2, 0.3, 0.4, 0.5],\n",
    "                       [0.3, 0.4, 0.5, 0.6]])\n",
    "    bias1 = np.array([0.4,0.5,0.6])\n",
    "\n",
    "    theta2 = np.array([[0.6, 0.5, 0.4], \n",
    "                       [0.5, 0.4, 0.3],\n",
    "                       [0.4, 0.3, 0.2]])\n",
    "    bias2 = np.array([0.4,0.3,0.2])\n",
    "\n",
    "    return [theta1, bias1, theta2, bias2]\n",
    "def predict(sigmoid):\n",
    "    if(sigmoid < 0.5):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def checking_accuration(data1,data2):\n",
    "    checking = np.zeros(table_count(data1), dtype=bool)\n",
    "    for i in range(table_count(data1)):\n",
    "        checking[i] = np.array_equal(data1.iloc[i].values, data2.iloc[i].values)   \n",
    "    return checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(training,r):\n",
    "    theta1 = np.array(r[0])\n",
    "    bias1 = np.array(r[1])\n",
    "    theta2 = np.array(r[2])\n",
    "    bias2 = np.array(r[3])\n",
    "    \n",
    "    error1 = 0\n",
    "    error2 = 0\n",
    "    error3 = 0\n",
    "\n",
    "    for i in range(table_count(training)):\n",
    "        h11 = h(training.iloc[i,:4],theta1[0,:4]) + bias1[0]\n",
    "        h12 = h(training.iloc[i,:4],theta1[1,:4]) + bias1[1]\n",
    "        h13 = h(training.iloc[i,:4],theta1[2,:4]) + bias1[2]\n",
    "\n",
    "        s11 = sigmoid(h11)\n",
    "        s12 = sigmoid(h12)\n",
    "        s13 = sigmoid(h13)\n",
    "    \n",
    "        h21 = s11 * theta2[0][0] + s12 * theta2[0][1] + s13 * theta2[0][2] + bias2[0]\n",
    "        h22 = s11 * theta2[1][0] + s12 * theta2[1][1] + s13 * theta2[1][2] + bias2[1]\n",
    "        h23 = s11 * theta2[2][0] + s12 * theta2[2][1] + s13 * theta2[2][2] + bias2[2]\n",
    "    \n",
    "        s21 = sigmoid(h21)\n",
    "        s22 = sigmoid(h22)\n",
    "        s23 = sigmoid(h23)\n",
    "    \n",
    "        error1 += (s21 - training.iloc[i,5])**2\n",
    "        error2 += (s22 - training.iloc[i,6])**2\n",
    "        error3 += (s23 - training.iloc[i,7])**2\n",
    "    \n",
    "        tau21 = 2*(s21 - training.iloc[i,5]) * (1-s21)*s21\n",
    "        dw21 = tau21 * s11\n",
    "        dw24 = tau21 * s12\n",
    "        dw27 = tau21 * s13\n",
    "    \n",
    "        tau22 = 2*(s22 - training.iloc[i,6]) * (1-s22)*s22\n",
    "        dw22 = tau22 * s11\n",
    "        dw25 = tau22 * s12\n",
    "        dw28 = tau22 * s13\n",
    "        \n",
    "        tau23 = 2*(s23 - training.iloc[i,7]) * (1-s23) * s23\n",
    "        dw23 = tau23 * s11\n",
    "        dw26 = tau23 * s12\n",
    "        dw29 = tau23 * s13\n",
    "    \n",
    "        tau11 = (tau21 * theta2[0,0] + tau22 * theta2[1,0] + tau23 * theta2[2,0]) * (1-s11) * s11\n",
    "        dw11 = tau11 * training.iloc[i,0]\n",
    "        dw14 = tau11 * training.iloc[i,1]\n",
    "        dw17 = tau11 * training.iloc[i,2]\n",
    "        dw110 = tau11 * training.iloc[i,3]\n",
    "\n",
    "        tau12 = (tau21 * theta2[0,1] + tau22 * theta2[1,1] + tau23 * theta2[2,1]) *(1-s12)*s12\n",
    "        dw12 = tau12 * training.iloc[i,0]\n",
    "        dw15 = tau12 * training.iloc[i,1]\n",
    "        dw18 = tau12 * training.iloc[i,2]\n",
    "        dw111 = tau12 * training.iloc[i,3]\n",
    "        \n",
    "        tau13 = (tau21 * theta2[0,2] + tau22 * theta2[1,2] + tau23 * theta2[2,2]) * (1-s13) * s13\n",
    "        dw13 = tau13 * training.iloc[i,0]\n",
    "        dw16 = tau13 * training.iloc[i,1]\n",
    "        dw19 = tau13 * training.iloc[i,2]\n",
    "        dw112 = tau13 * training.iloc[i,3]\n",
    "    \n",
    "        dw2 = np.array([[dw21, dw24, dw27],\n",
    "                        [dw22, dw25, dw28],\n",
    "                        [dw23, dw26, dw29]])\n",
    "        \n",
    "        dbias2 = np.array([tau21, tau22, tau23])\n",
    "\n",
    "        dw1 = np.array([[dw11, dw14, dw17, dw110],\n",
    "                        [dw12, dw15, dw18, dw111],\n",
    "                        [dw13, dw16, dw19, dw112]])\n",
    "\n",
    "        dbias1 = np.array([tau11, tau12, tau13])\n",
    "        \n",
    "        theta1 = theta1 - ALPHA * dw1\n",
    "        bias1 = bias1 - ALPHA * dbias1\n",
    "        theta2 = theta2 - ALPHA * dw2\n",
    "        bias2 = bias2 - ALPHA * dbias2\n",
    "        \n",
    "    error = np.array([error1, error2,error3])\n",
    "    error = error/table_count(training)\n",
    "    error = np.mean(error)\n",
    "    \n",
    "    return np.array([[error],[theta1, bias1, theta2, bias2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testing, r):\n",
    "    theta1 = np.array(r[0])\n",
    "    bias1 = np.array(r[1])\n",
    "    theta2 = np.array(r[2])\n",
    "    bias2 = np.array(r[3])\n",
    "    \n",
    "    prediksi1 = np.zeros(table_count(testing))\n",
    "    prediksi2 = np.zeros(table_count(testing))\n",
    "    prediksi3 = np.zeros(table_count(testing))\n",
    "\n",
    "    error1 = 0\n",
    "    error2 = 0\n",
    "    error3 = 0\n",
    "    \n",
    "    for i in range(table_count(testing)):\n",
    "        h11 = h(testing.iloc[i,:4],theta1[0,:4]) + bias1[0]\n",
    "        h12 = h(testing.iloc[i,:4],theta1[1,:4]) + bias1[1]\n",
    "        h13 = h(testing.iloc[i,:4],theta1[2,:4]) + bias1[2]\n",
    "\n",
    "        s11 = sigmoid(h11)\n",
    "        s12 = sigmoid(h12)\n",
    "        s13 = sigmoid(h13)\n",
    "    \n",
    "        h21 = s11 * theta2[0][0] + s12 * theta2[0][1] + s13 * theta2[0][2] + bias2[0]\n",
    "        h22 = s11 * theta2[1][0] + s12 * theta2[1][1] + s13 * theta2[1][2] + bias2[1]\n",
    "        h23 = s11 * theta2[2][0] + s12 * theta2[2][1] + s13 * theta2[2][2] + bias2[2]\n",
    "    \n",
    "        s21 = sigmoid(h21)\n",
    "        s22 = sigmoid(h22)\n",
    "        s23 = sigmoid(h23)\n",
    "        \n",
    "        prediksi1[i] = predict(s21)\n",
    "        prediksi2[i] = predict(s22)\n",
    "        prediksi3[i] = predict(s23)\n",
    "    \n",
    "        error1 += (s21 - testing.iloc[i,5])**2\n",
    "        error2 += (s22 - testing.iloc[i,6])**2\n",
    "        error3 += (s23 - testing.iloc[i,7])**2\n",
    "        \n",
    "    error = np.array([error1, error2,error3])\n",
    "    error = error/table_count(testing)\n",
    "    error = np.mean(error)\n",
    "    \n",
    "    predict_table = pd.DataFrame({'prediksi 1':prediksi1,\n",
    "                                  'prediksi 2':prediksi2,\n",
    "                                  'prediksi 3':prediksi3})\n",
    "    \n",
    "    text.append(str(predict_table)+\"\\n\")\n",
    "    \n",
    "    conditional = checking_accuration(testing.iloc[:,5:8], predict_table)\n",
    "    unique, count = np.unique(conditional, return_counts=True)\n",
    "    c = np.where(unique == True)\n",
    "    if(c[0].size != 0):   \n",
    "        akurasi = (float(count[c[0][0]]) / table_count(testing)) * 100\n",
    "        text.append(\"Akurasi \"+str(akurasi)+\"\\n\")\n",
    "    else:\n",
    "        akurasi = 0\n",
    "        text.append(\"Akurasi \"+str(akurasi)+\"\\n\")\n",
    "    return np.array([error,akurasi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Training tiap Epoch\n",
      "[0.28294279 0.22024399 0.21784755 0.21327263 0.20498909 0.19379963\n",
      " 0.18185024 0.17077894 0.16128202 0.15344759 0.14708935 0.14194368\n",
      " 0.13775925 0.13432627 0.13147924 0.12909054 0.12706243 0.12531994\n",
      " 0.12380518 0.12247316 0.12128853 0.12022338 0.11925541 0.11836675\n",
      " 0.117543   0.1167725  0.11604582 0.11535533 0.11469489 0.11405958\n",
      " 0.1134455  0.11284958 0.11226946 0.11170333 0.11114986 0.1106081\n",
      " 0.11007735 0.10955719 0.10904734 0.10854765 0.10805806 0.10757856\n",
      " 0.10710916 0.1066499  0.10620079 0.10576186 0.1053331  0.10491446\n",
      " 0.1045059  0.10410732 0.10371861 0.10333963 0.10297023 0.10261021\n",
      " 0.10225937 0.10191752 0.10158441 0.10125981 0.10094349 0.1006352\n",
      " 0.10033468 0.1000417  0.099756   0.09947734 0.09920549 0.0989402\n",
      " 0.09868126 0.09842843 0.0981815  0.09794027 0.09770453 0.0974741\n",
      " 0.09724878 0.0970284  0.0968128  0.0966018  0.09639525 0.096193\n",
      " 0.09599492 0.09580087 0.09561071 0.09542432 0.09524159 0.0950624\n",
      " 0.09488665 0.09471423 0.09454505 0.094379   0.09421601 0.09405598\n",
      " 0.09389883 0.09374448 0.09359286 0.0934439  0.09329751 0.09315365\n",
      " 0.09301224 0.09287321 0.09273652 0.0926021 ]\n",
      "Error Testing tiap Epoch\n",
      "[0.2715923  0.24468801 0.24198267 0.23762137 0.23073647 0.22068166\n",
      " 0.20830134 0.19568021 0.1843517  0.17486534 0.16717107 0.16099004\n",
      " 0.15601028 0.15196037 0.14862514 0.14584043 0.14348258 0.14145868\n",
      " 0.13969857 0.13814903 0.13676942 0.13552857 0.13440246 0.13337258\n",
      " 0.13242468 0.13154778 0.13073346 0.12997531 0.12926844 0.12860913\n",
      " 0.12799456 0.12742253 0.12689133 0.12639954 0.12594593 0.12552937\n",
      " 0.12514876 0.12480297 0.12449083 0.12421107 0.12396235 0.12374325\n",
      " 0.12355222 0.1233877  0.12324803 0.12313152 0.12303646 0.12296113\n",
      " 0.12290383 0.12286287 0.12283662 0.1228235  0.12282199 0.12283065\n",
      " 0.12284811 0.1228731  0.12290444 0.12294102 0.12298183 0.12302597\n",
      " 0.12307258 0.12312093 0.12317034 0.12322021 0.12327001 0.12331929\n",
      " 0.12336764 0.12341472 0.12346023 0.12350392 0.12354559 0.12358508\n",
      " 0.12362223 0.12365696 0.12368919 0.12371885 0.12374593 0.1237704\n",
      " 0.12379226 0.12381153 0.12382824 0.12384243 0.12385412 0.12386339\n",
      " 0.12387029 0.12387487 0.1238772  0.12387735 0.1238754  0.1238714\n",
      " 0.12386544 0.12385759 0.12384791 0.12383648 0.12382338 0.12380866\n",
      " 0.1237924  0.12377466 0.12375552 0.12373503]\n",
      "Akurasi tiap Epoch\n",
      "[ 0.          0.          0.          0.          0.          2.\n",
      " 13.33333333 13.33333333 14.66666667 53.33333333 62.66666667 64.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667 66.66666667\n",
      " 66.66666667 66.66666667 66.66666667 66.66666667]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2319ec057b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_training_epoch = np.empty(EPOCH)\n",
    "error_testing_epoch = np.empty(EPOCH)\n",
    "akurasi_epoch = np.empty(EPOCH)\n",
    "\n",
    "error_training = 0\n",
    "error_testing = 0\n",
    "akurasi = 0\n",
    "\n",
    "testing = df.iloc[0:30]\n",
    "training = df.iloc[30:150]\n",
    "\n",
    "text.append(str(testing)+\"\\n\")\n",
    "\n",
    "training_result = backprop(training, theta_bias_initiation())\n",
    "error_training = error_training + training_result[0][0]\n",
    "\n",
    "testing_result = test(testing,training_result[1])\n",
    "error_testing = error_testing + testing_result[0]\n",
    "akurasi = akurasi + testing_result[1]\n",
    "\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    testing = df.iloc[30:60]\n",
    "    training = df.iloc[0:30]\n",
    "    training = training.append(df.iloc[60:150])\n",
    "\n",
    "    text.append(str(testing)+\"\\n\")\n",
    "    \n",
    "    training_result = backprop(training,training_result[1])\n",
    "    error_training = error_training + training_result[0][0]\n",
    "\n",
    "    testing_result = test(testing,training_result[1])\n",
    "    error_testing = error_testing + testing_result[0]\n",
    "    akurasi = akurasi + testing_result[1]\n",
    "\n",
    "    testing = df.iloc[60:90]\n",
    "    training = df.iloc[0:60]\n",
    "    training = training.append(df.iloc[90:150])\n",
    "\n",
    "    text.append(str(testing)+\"\\n\")\n",
    "    \n",
    "    training_result = backprop(training,training_result[1])\n",
    "    error_training = error_training + training_result[0][0]\n",
    "\n",
    "    testing_result = test(testing,training_result[1])\n",
    "    error_testing = error_testing + testing_result[0]\n",
    "    akurasi = akurasi + testing_result[1]\n",
    "\n",
    "    testing = df.iloc[90:120]\n",
    "    training = df.iloc[0:90]\n",
    "    training = training.append(df.iloc[120:150])\n",
    "\n",
    "    text.append(str(testing)+\"\\n\")\n",
    "    \n",
    "    training_result = backprop(training,training_result[1])\n",
    "    error_training = error_training + training_result[0][0]\n",
    "\n",
    "    testing_result = test(testing,training_result[1])\n",
    "    error_testing = error_testing + testing_result[0]\n",
    "    akurasi = akurasi + testing_result[1]\n",
    "\n",
    "    testing = df.iloc[120:150]\n",
    "    training = df.iloc[0:120]\n",
    "    \n",
    "    text.append(str(testing)+\"\\n\")\n",
    "    \n",
    "    training_result = backprop(training,training_result[1])\n",
    "    error_training = error_training + training_result[0][0]\n",
    "    \n",
    "    testing_result = test(testing,training_result[1])\n",
    "    error_testing = error_testing + testing_result[0]\n",
    "    akurasi = akurasi + testing_result[1]\n",
    "    \n",
    "    mean_error_training = error_training/5\n",
    "    mean_error_testing = error_testing/5\n",
    "    mean_akurasi = akurasi/5\n",
    "    error_training_epoch[i] = mean_error_training\n",
    "    error_testing_epoch[i] = mean_error_testing\n",
    "    akurasi_epoch[i] = mean_akurasi\n",
    "    \n",
    "    if(i<EPOCH-1):\n",
    "        text.append(\"Epoch \"+str(i+1)+\"\\n\")\n",
    "        text.append(\"=======\")\n",
    "        #print(\"Epoch\", str(EPOCH+1))\n",
    "        error_training = 0\n",
    "        error_testing = 0\n",
    "        akurasi = 0\n",
    "\n",
    "        testing = df.iloc[0:30]\n",
    "        training = df.iloc[30:150]\n",
    "        text.append(str(testing)+\"\\n\")\n",
    "        #print(testing)\n",
    "        #print( training\n",
    "\n",
    "        #print( theta_bias_initiation()\n",
    "        training_result = backprop(training, training_result[1])\n",
    "        error_training = error_training + training_result[0][0]\n",
    "        #print( training_result\n",
    "        testing_result = test(testing,training_result[1])\n",
    "        error_testing = error_testing + testing_result[0]\n",
    "        akurasi = akurasi + testing_result[1]\n",
    "\n",
    "        #print( error_training\n",
    "        #print( error_testing\n",
    "        #print(akurasi)\n",
    "\n",
    "print(\"Error Training tiap Epoch\")\n",
    "print(error_training_epoch)\n",
    "print(\"Error Testing tiap Epoch\")\n",
    "print(error_testing_epoch)\n",
    "print(\"Akurasi tiap Epoch\")\n",
    "print(akurasi_epoch)\n",
    "\n",
    "plt.plot(error_training_epoch,'r',error_testing_epoch,'g')\n",
    "#plt.scatter(np.arange(100),akurasi_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
